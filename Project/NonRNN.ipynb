{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9648f20b4b0f064d",
   "metadata": {},
   "source": [
    "# Notebook for testing Scikit Learn models\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import matplotlib.ticker as tkr\n",
    "import math\n",
    "import keras\n",
    "import os.path\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import multilabel_confusion_matrix, max_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, confusion_matrix, recall_score \n",
    "from sklearn.metrics import f1_score, auc, matthews_corrcoef, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression, mutual_info_regression, SelectKBest\n",
    "\n",
    "\n",
    "from os import path\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(20)\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import pearsonr\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score, max_error\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "    \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ba09484b4bad0",
   "metadata": {},
   "source": [
    "## Helper Methods (Function Definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be4f57cf2e5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, filename):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "        file_handler = logging.FileHandler(filename)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        \n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        \n",
    "        self.logger.addHandler(file_handler)\n",
    "\n",
    "    def log(self, message):\n",
    "        self.logger.info(message)\n",
    "\n",
    "import sys\n",
    "\n",
    "def spcc(y_true, y_pred, **kwargs):\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "    return corr\n",
    "    \n",
    "    \n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    #dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "    \n",
    "#Takes a dataframe with the holiday field and returns encoded dataframe.\n",
    "def onehotholiday(select):\n",
    "    X_2 = select[['Holiday']]\n",
    "    # TODO: create a OneHotEncoder object, and fit it to all of X\n",
    "    # 1. INSTANTIATE\n",
    "    enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "    \n",
    "    # 2. FIT\n",
    "    enc.fit(X_2)\n",
    "    \n",
    "    # 3. Transform\n",
    "    onehotlabels = enc.transform(X_2)\n",
    "    # creating a list of column names \n",
    "    column_values = []\n",
    "    for i in range(np.shape(onehotlabels)[1]):\n",
    "            column_values.append('A'+str(i))\n",
    "\n",
    "    # creating the dataframe \n",
    "    onehotholiday = pd.DataFrame(data = onehotlabels,columns = column_values)\n",
    "\n",
    "    dataset = select.drop(columns=['Holiday'])\n",
    "    dataset = select.join(onehotholiday)\n",
    "    df1 = dataset.pop('2to5')\n",
    "    dataset['2to5']=df1 # add b series as a 'new' column\n",
    "    dataset2=dataset\n",
    "    dataset2 = dataset2.drop(columns=['Holiday'])\n",
    "    return dataset2\n",
    "    \n",
    "\n",
    "def add_lookback(dataset, look_back, df):\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:(i+look_back)]['2to5']\n",
    "        a = a.values\n",
    "        for j in range(len(a)):\n",
    "            df[j][i]= a[j]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbeb4859aa7e4a",
   "metadata": {},
   "source": [
    "## Initialization of Tested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8e3a64bb46b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nn = MultiOutputRegressor( MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 5, 5, 5, 5), random_state=42) )\n",
    "stack_nn =  MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 5, 5, 5, 5), random_state=42)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=7))\n",
    "stack_neigh = KNeighborsRegressor(n_neighbors=7)\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "LR = LinearRegression()\n",
    "rid = Ridge(alpha=1.0)\n",
    "et = ExtraTreesRegressor(n_estimators=1000, random_state=0)\n",
    "\n",
    "stack = MultiOutputRegressor(StackingCVRegressor(regressors=(LR, rid, et, stack_neigh, stack_nn),\n",
    "                            meta_regressor=rid, \n",
    "                            random_state=42,\n",
    "                            use_features_in_secondary=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lgbm = MultiOutputRegressor(lgb.LGBMRegressor(num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=1000,n_jobs=-1))\n",
    "\n",
    "XGBModel = MultiOutputRegressor(XGBRegressor(learning_rate =0.05,\n",
    " n_estimators=2000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0.1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror',\n",
    " nthread=5,\n",
    " scale_pos_weight=1,\n",
    " seed=21,\n",
    " eval_metric = ['mae']))\n",
    "\n",
    "ETCModel  = MultiOutputRegressor(ExtraTreesRegressor(n_estimators=1000, random_state=0))\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "gpr = MultiOutputRegressor(GaussianProcessRegressor())\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "Lcv = MultiOutputRegressor(LassoCV(cv=5, random_state=0))\n",
    "LR = MultiOutputRegressor(LinearRegression())\n",
    "SGD = MultiOutputRegressor(SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = MultiOutputRegressor(Ridge(alpha=1.0))\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "els = MultiOutputRegressor(ElasticNetCV(cv=10, random_state=0,max_iter=100000) )  \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor   \n",
    "dt = MultiOutputRegressor(DecisionTreeRegressor(random_state=0,criterion=\"mae\") )\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "kridge = MultiOutputRegressor(KernelRidge())\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "bridge = MultiOutputRegressor(BayesianRidge())\n",
    "\n",
    "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
    "svr = MultiOutputRegressor(SVR())\n",
    "nusvr = MultiOutputRegressor(NuSVR())\n",
    "linsvr = MultiOutputRegressor(LinearSVR())\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "reg3 = LinearRegression()\n",
    "reg4 = DecisionTreeRegressor(random_state=0,criterion=\"mae\")\n",
    "reg5 = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\n",
    "VR = MultiOutputRegressor(\n",
    "    VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3), ('dt',reg4), ('sgd',reg5)]))\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nn = MultiOutputRegressor( MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 5, 5, 5, 5), random_state=42) )\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d0c3bc3215151",
   "metadata": {},
   "source": [
    "## Actual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1947d6ea0a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# fix random seed for reproducibility\n",
    "# load the dataset\n",
    "dataframe = pd.read_csv('Data/RestaurantDataVets_All_2to5.csv')\n",
    "data = dataframe.drop(columns=['Index','Group','DMY','MissingPrevDays','DailyAvg','DailyBusyness'])\n",
    "\n",
    "lookback=20\n",
    "dataframe_removed_lookback = data.drop([x for x in range(lookback)])\n",
    "\n",
    "for i in range(lookback):\n",
    "    dataframe_removed_lookback[i] = 1.0\n",
    "    \n",
    "df = dataframe_removed_lookback[['Year', 'Day', 'January','February',\n",
    "                         'March','April','May','June','July',\n",
    "                         'August', 'September', 'October', 'November',\n",
    "                         'December','Sunday', 'Monday', 'Tuesday',\n",
    "                         'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Holiday', 'Carnival', \n",
    "                         'LentFasting','Ramadan','ChristmasSeason',\n",
    "                         'WeeklyAvg','MinSales','MaxSales',\n",
    "                         'WeeklyBusyness',\n",
    "                         0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
    "                          14, 15, 16, 17, 18, 19,      \n",
    "                         '2to5']]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Objects need to be converted to float due to missing values at load time.\n",
    "#df[\"DailyAvg\"] = df.DailyAvg.astype(float)\n",
    "df[\"WeeklyAvg\"] = df.WeeklyAvg.astype(float)\n",
    "df[\"MinSales\"] = df.MinSales.astype(float)\n",
    "df[\"MaxSales\"] = df.MaxSales.astype(float)\n",
    "#df[\"DailyBusyness\"] = df.DailyBusyness.astype(float)\n",
    "df[\"WeeklyBusyness\"] = df.WeeklyBusyness.astype(float)\n",
    "\n",
    "lb_data = add_lookback(data, lookback, df)\n",
    "lb_data = lb_data.reset_index(drop=True)\n",
    "\n",
    "hotdata = onehotholiday(lb_data)\n",
    "hotdata = hotdata.drop(columns=[14,15,16,17,18,19])\n",
    "\n",
    "hot_numcols = len(hotdata.columns)\n",
    "dataset = hotdata.values\n",
    "\n",
    "lbset=lb_data.values\n",
    "lb_numcols =  len(lb_data.columns)\n",
    "\n",
    "print(\"train_df Shape:\" ,lb_data.shape)\n",
    "print(\"After encoding:\", hotdata.shape)\n",
    "\n",
    "X=dataset[:, 0:hot_numcols-1]\n",
    "y=lbset[:, lb_numcols-7:lb_numcols]\n",
    "\n",
    "scaler = preprocessing.RobustScaler()\n",
    "X = scaler.fit_transform(X,y)\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "clflist=[stack,LR,VR,linsvr,SGD , nn, svr, nusvr, bridge, dt, els,LR,ridge,kridge, \n",
    "         Lcv,  gpr, ETCModel, neigh, XGBModel, lgbm]  \n",
    "#,\n",
    "recording = pd.DataFrame(clflist,columns=['Model'])\n",
    "\n",
    "scoring = {\n",
    "        'mae': 'neg_mean_absolute_error',\n",
    "        'mse' : 'neg_mean_squared_error',\n",
    "        'custom': make_scorer(spcc, greater_is_better=True)\n",
    "    }\n",
    "\n",
    "j_arr = []\n",
    "for j in range (71):\n",
    "    print('Keeping k-best features where k = ', (j+1))\n",
    "    mae_arr = []\n",
    "    max_arr = []\n",
    "    rmse_arr = []\n",
    "    corr_arr = []\n",
    "\n",
    "    for x in range(len(clflist)):\n",
    "        corr_arr.append(0)\n",
    "        mae_arr.append(0)\n",
    "        rmse_arr.append(0)\n",
    "        max_arr.append(0)\n",
    "    i=0\n",
    "    for clf in clflist:\n",
    "            feat_reduction = SelectKBest(f_regression, k=j+1) \n",
    "            X_new = feat_reduction.fit_transform(X,y[:,0])\n",
    "            print(clf) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=221, random_state=42, shuffle=False)\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            meansq = keras.metrics.mean_squared_error(y_test.flatten(), y_pred.flatten()).numpy()\n",
    "            meanabs = keras.metrics.mean_absolute_error(y_test.flatten(), y_pred.flatten()).numpy()\n",
    "            print(\"MSE = \"+str(meansq))\n",
    "            print(\"MAE = \"+str(meanabs))\n",
    "            mae_arr[i]=meanabs\n",
    "            i= i+1\n",
    "            print('_______________________________________________________________________________')\n",
    "    \n",
    "    j_arr.append(j+1)\n",
    "    recording['Run'+str(j)] = mae_arr\n",
    "\n",
    "corr_arr = np.array(corr_arr)\n",
    "print(\"COMPLETE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
